import sys
import sentencepiece as spm
src_lang = sys.argv[1]
trg_lang = sys.argv[2]
# Trains the SentencePiece Models with BPE for src_lang and trg_lang from the training data and saves it as model and vocab files. These are used for tokenisation before training by the OpenNMT 
spm.SentencePieceTrainer.train(input=f'data/{src_lang}-{trg_lang}/trainconcat.{src_lang}.{trg_lang}', model_prefix=f'data/models/spm_model.bpe.{src_lang}.{trg_lang}', vocab_size=2000, model_type='bpe')
# Delete the .vocab generated by Sentence Piece 